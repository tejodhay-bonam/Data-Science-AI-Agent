{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfd516f4",
   "metadata": {},
   "source": [
    "### Subtask 1: Load the dataset\n",
    "- Load the dataset from the specified CSV file located at 'F:\\ITShoulders\\AI_Data_Science_agent\\temp_uploads\\housing.csv' into a pandas DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b999d4c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T23:05:15.795752Z",
     "iopub.status.busy": "2025-05-21T23:05:15.794746Z",
     "iopub.status.idle": "2025-05-21T23:05:16.638680Z",
     "shell.execute_reply": "2025-05-21T23:05:16.638680Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "0    -122.23     37.88                41.0        880.0           129.0   \n",
      "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
      "2    -122.24     37.85                52.0       1467.0           190.0   \n",
      "3    -122.25     37.85                52.0       1274.0           235.0   \n",
      "4    -122.25     37.85                52.0       1627.0           280.0   \n",
      "\n",
      "   population  households  median_income  median_house_value ocean_proximity  \n",
      "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
      "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
      "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
      "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
      "4       565.0       259.0         3.8462            342200.0        NEAR BAY  \n"
     ]
    }
   ],
   "source": [
    "# Load the dataset into a pandas DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "file_path = r'F:\\ITShoulders\\AI_Data_Science_agent\\temp_uploads\\housing.csv'\n",
    "housing_df = pd.read_csv(file_path)\n",
    "print(housing_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4da967c",
   "metadata": {},
   "source": [
    "### Subtask 2: Initial Data Exploration\n",
    "- Perform initial data exploration by viewing the first few rows of the DataFrame, checking the data types of each column, and identifying any missing values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "586d4c0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T23:05:16.640689Z",
     "iopub.status.busy": "2025-05-21T23:05:16.640689Z",
     "iopub.status.idle": "2025-05-21T23:05:16.658336Z",
     "shell.execute_reply": "2025-05-21T23:05:16.658336Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           20640 non-null  float64\n",
      " 1   latitude            20640 non-null  float64\n",
      " 2   housing_median_age  20640 non-null  float64\n",
      " 3   total_rooms         20640 non-null  float64\n",
      " 4   total_bedrooms      20433 non-null  float64\n",
      " 5   population          20640 non-null  float64\n",
      " 6   households          20640 non-null  float64\n",
      " 7   median_income       20640 non-null  float64\n",
      " 8   median_house_value  20640 non-null  float64\n",
      " 9   ocean_proximity     20640 non-null  object \n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.6+ MB\n",
      "None\n",
      "\n",
      "Missing values in each column:\n",
      "longitude               0\n",
      "latitude                0\n",
      "housing_median_age      0\n",
      "total_rooms             0\n",
      "total_bedrooms        207\n",
      "population              0\n",
      "households              0\n",
      "median_income           0\n",
      "median_house_value      0\n",
      "ocean_proximity         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Initial data exploration\n",
    "# Checking data types and missing values in the DataFrame\n",
    "print(housing_df.info())\n",
    "print('\\nMissing values in each column:')\n",
    "print(housing_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8a0e4d",
   "metadata": {},
   "source": [
    "### Subtask 3: Exploratory Data Analysis (EDA)\n",
    "- Conduct exploratory data analysis (EDA) to derive insights, including generating statistical summaries, visualizing the distribution of key features like house prices, and analyzing correlations between features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e37cdf2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T23:05:16.660375Z",
     "iopub.status.busy": "2025-05-21T23:05:16.660375Z",
     "iopub.status.idle": "2025-05-21T23:05:19.912477Z",
     "shell.execute_reply": "2025-05-21T23:05:19.912477Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          longitude      latitude  housing_median_age   total_rooms  \\\n",
      "count  20640.000000  20640.000000        20640.000000  20640.000000   \n",
      "mean    -119.569704     35.631861           28.639486   2635.763081   \n",
      "std        2.003532      2.135952           12.585558   2181.615252   \n",
      "min     -124.350000     32.540000            1.000000      2.000000   \n",
      "25%     -121.800000     33.930000           18.000000   1447.750000   \n",
      "50%     -118.490000     34.260000           29.000000   2127.000000   \n",
      "75%     -118.010000     37.710000           37.000000   3148.000000   \n",
      "max     -114.310000     41.950000           52.000000  39320.000000   \n",
      "\n",
      "       total_bedrooms    population    households  median_income  \\\n",
      "count    20433.000000  20640.000000  20640.000000   20640.000000   \n",
      "mean       537.870553   1425.476744    499.539680       3.870671   \n",
      "std        421.385070   1132.462122    382.329753       1.899822   \n",
      "min          1.000000      3.000000      1.000000       0.499900   \n",
      "25%        296.000000    787.000000    280.000000       2.563400   \n",
      "50%        435.000000   1166.000000    409.000000       3.534800   \n",
      "75%        647.000000   1725.000000    605.000000       4.743250   \n",
      "max       6445.000000  35682.000000   6082.000000      15.000100   \n",
      "\n",
      "       median_house_value  \n",
      "count        20640.000000  \n",
      "mean        206855.816909  \n",
      "std         115395.615874  \n",
      "min          14999.000000  \n",
      "25%         119600.000000  \n",
      "50%         179700.000000  \n",
      "75%         264725.000000  \n",
      "max         500001.000000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TEJODHAY\\AppData\\Local\\Temp\\ipykernel_62636\\4139680978.py:15: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'NEAR BAY'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Analyzing correlations between features\u001b[39;00m\n\u001b[32m     18\u001b[39m plt.figure(figsize=(\u001b[32m12\u001b[39m, \u001b[32m8\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m correlation_matrix = \u001b[43mhousing_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcorr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m sns.heatmap(correlation_matrix, annot=\u001b[38;5;28;01mTrue\u001b[39;00m, cmap=\u001b[33m'\u001b[39m\u001b[33mcoolwarm\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     21\u001b[39m plt.title(\u001b[33m'\u001b[39m\u001b[33mCorrelation Matrix of Housing Features\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mF:\\ITShoulders\\AI_Data_Science_agent\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:11049\u001b[39m, in \u001b[36mDataFrame.corr\u001b[39m\u001b[34m(self, method, min_periods, numeric_only)\u001b[39m\n\u001b[32m  11047\u001b[39m cols = data.columns\n\u001b[32m  11048\u001b[39m idx = cols.copy()\n\u001b[32m> \u001b[39m\u001b[32m11049\u001b[39m mat = \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m  11051\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m method == \u001b[33m\"\u001b[39m\u001b[33mpearson\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m  11052\u001b[39m     correl = libalgos.nancorr(mat, minp=min_periods)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mF:\\ITShoulders\\AI_Data_Science_agent\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:1993\u001b[39m, in \u001b[36mDataFrame.to_numpy\u001b[39m\u001b[34m(self, dtype, copy, na_value)\u001b[39m\n\u001b[32m   1991\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1992\u001b[39m     dtype = np.dtype(dtype)\n\u001b[32m-> \u001b[39m\u001b[32m1993\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1994\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dtype:\n\u001b[32m   1995\u001b[39m     result = np.asarray(result, dtype=dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mF:\\ITShoulders\\AI_Data_Science_agent\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1694\u001b[39m, in \u001b[36mBlockManager.as_array\u001b[39m\u001b[34m(self, dtype, copy, na_value)\u001b[39m\n\u001b[32m   1692\u001b[39m         arr.flags.writeable = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1693\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1694\u001b[39m     arr = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[32m   1696\u001b[39m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[32m   1698\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib.no_default:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mF:\\ITShoulders\\AI_Data_Science_agent\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1753\u001b[39m, in \u001b[36mBlockManager._interleave\u001b[39m\u001b[34m(self, dtype, na_value)\u001b[39m\n\u001b[32m   1751\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1752\u001b[39m         arr = blk.get_values(dtype)\n\u001b[32m-> \u001b[39m\u001b[32m1753\u001b[39m     \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m]\u001b[49m = arr\n\u001b[32m   1754\u001b[39m     itemmask[rl.indexer] = \u001b[32m1\u001b[39m\n\u001b[32m   1756\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m itemmask.all():\n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: 'NEAR BAY'"
     ]
    }
   ],
   "source": [
    "# Exploratory Data Analysis\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Generating statistical summaries\n",
    "stats_summary = housing_df.describe()\n",
    "print(stats_summary)\n",
    "\n",
    "# Visualizing the distribution of median house value\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(housing_df['median_house_value'], bins=30, kde=True, color='blue')\n",
    "plt.title('Distribution of Median House Value')\n",
    "plt.xlabel('Median House Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Analyzing correlations between features\n",
    "plt.figure(figsize=(12, 8))\n",
    "correlation_matrix = housing_df.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix of Housing Features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cca6619",
   "metadata": {},
   "source": [
    "### Handling error\n",
    "- The error occurred because the 'ocean_proximity' column is of object type and not numeric.\n",
    "- We will exclude the 'ocean_proximity' column for the correlation matrix as it is a categorical feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf40412b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T23:05:19.915511Z",
     "iopub.status.busy": "2025-05-21T23:05:19.914504Z",
     "iopub.status.idle": "2025-05-21T23:05:20.139867Z",
     "shell.execute_reply": "2025-05-21T23:05:20.139361Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TEJODHAY\\AppData\\Local\\Temp\\ipykernel_62636\\2011786375.py:6: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Corrected Correlation Matrix Excluding 'ocean_proximity'\n",
    "plt.figure(figsize=(12, 8))\n",
    "correlation_matrix = housing_df.drop(columns=['ocean_proximity']).corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix of Numeric Housing Features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d796ac5",
   "metadata": {},
   "source": [
    "### Subtask 4: Data Preprocessing\n",
    "- Preprocess the data by handling missing values, encoding categorical data, and normalizing numerical features, preparing the dataset for model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "674e7a10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T23:05:20.142187Z",
     "iopub.status.busy": "2025-05-21T23:05:20.142005Z",
     "iopub.status.idle": "2025-05-21T23:05:20.618313Z",
     "shell.execute_reply": "2025-05-21T23:05:20.618313Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing completed.\n",
      "Processed feature shape: (20640, 13)\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Separate target variable from features\n",
    "X = housing_df.drop('median_house_value', axis=1)\n",
    "y = housing_df['median_house_value']\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "numerical_cols = X.select_dtypes(include=['float64']).columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Preprocessing pipeline for numerical data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Preprocessing pipeline for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('encoder', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine numerical and categorical transformations\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols),\n",
    "    ])\n",
    "\n",
    "# Preprocess the data\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "print('Data preprocessing completed.')\n",
    "print(f'Processed feature shape: {X_processed.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ce10b4",
   "metadata": {},
   "source": [
    "### Subtask 5: Split Dataset\n",
    "- Split the dataset into training and testing subsets to facilitate model validation and performance evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad028b78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T23:05:20.620317Z",
     "iopub.status.busy": "2025-05-21T23:05:20.619317Z",
     "iopub.status.idle": "2025-05-21T23:05:20.629693Z",
     "shell.execute_reply": "2025-05-21T23:05:20.629693Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split completed.\n",
      "Training data shape: (16512, 13), (16512,)\n",
      "Testing data shape: (4128, 13), (4128,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n",
    "print('Data split completed.')\n",
    "print(f'Training data shape: {X_train.shape}, {y_train.shape}')\n",
    "print(f'Testing data shape: {X_test.shape}, {y_test.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de2b8ce",
   "metadata": {},
   "source": [
    "### Subtask 6: Train Multiple Predictive Models\n",
    "- Train multiple predictive models for house prices, including but not limited to techniques like linear regression, decision tree, and random forest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41ca8df1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T23:05:20.631704Z",
     "iopub.status.busy": "2025-05-21T23:05:20.630705Z",
     "iopub.status.idle": "2025-05-21T23:05:31.429746Z",
     "shell.execute_reply": "2025-05-21T23:05:31.429746Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training completed.\n"
     ]
    }
   ],
   "source": [
    "# Train multiple predictive models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Instantiate the models\n",
    "linear_model = LinearRegression()\n",
    "decision_tree_model = DecisionTreeRegressor(random_state=42)\n",
    "random_forest_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Train the models\n",
    "linear_model.fit(X_train, y_train)\n",
    "decision_tree_model.fit(X_train, y_train)\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "\n",
    "print('Model training completed.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa5dea8",
   "metadata": {},
   "source": [
    "### Subtask 7: Evaluate and Compare Models\n",
    "- Evaluate and compare the models' performance using metrics such as Mean Absolute Error (MAE) and R-squared score to find out which model predicts more accurately.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b7d4066",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T23:05:31.432745Z",
     "iopub.status.busy": "2025-05-21T23:05:31.432745Z",
     "iopub.status.idle": "2025-05-21T23:05:31.535647Z",
     "shell.execute_reply": "2025-05-21T23:05:31.535161Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression - MAE: 50670.73824097192, R-squared: 0.6254240620553605\n",
      "Decision Tree - MAE: 43600.67151162791, R-squared: 0.6354554029044672\n",
      "Random Forest - MAE: 31643.65566860465, R-squared: 0.8169555593071559\n"
     ]
    }
   ],
   "source": [
    "# Evaluate and compare models\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# Function to evaluate model performance\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    predictions = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    return mae, r2\n",
    "\n",
    "# Evaluate Linear Regression model\n",
    "linear_mae, linear_r2 = evaluate_model(linear_model, X_test, y_test)\n",
    "\n",
    "# Evaluate Decision Tree model\n",
    "decision_tree_mae, decision_tree_r2 = evaluate_model(decision_tree_model, X_test, y_test)\n",
    "\n",
    "# Evaluate Random Forest model\n",
    "random_forest_mae, random_forest_r2 = evaluate_model(random_forest_model, X_test, y_test)\n",
    "\n",
    "# Print evaluation results\n",
    "print(f\"Linear Regression - MAE: {linear_mae}, R-squared: {linear_r2}\")\n",
    "print(f\"Decision Tree - MAE: {decision_tree_mae}, R-squared: {decision_tree_r2}\")\n",
    "print(f\"Random Forest - MAE: {random_forest_mae}, R-squared: {random_forest_r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc532f2f",
   "metadata": {},
   "source": [
    "### Subtask 8: Identify Best-Performing Model\n",
    "- Based on the evaluation, identify and suggest the best-performing model for predicting house prices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52646505",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T23:05:31.537183Z",
     "iopub.status.busy": "2025-05-21T23:05:31.537183Z",
     "iopub.status.idle": "2025-05-21T23:05:31.540508Z",
     "shell.execute_reply": "2025-05-21T23:05:31.540012Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Random Forest model is identified as the best-performing model based on evaluation metrics.\n"
     ]
    }
   ],
   "source": [
    "# Identify and suggest the best-performing model\n",
    "# Based on MAE and R-squared scores from previous evaluations, the Random Forest model performs the best.\n",
    "best_model = random_forest_model\n",
    "\n",
    "print(\"The Random Forest model is identified as the best-performing model based on evaluation metrics.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758a5379",
   "metadata": {},
   "source": [
    "### Subtask 9: Develop Production-Ready Inference Function\n",
    "- Develop a production-ready function that uses the best model to produce house price predictions, incorporating any necessary data preprocessing within the function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7e2a7c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T23:05:31.541422Z",
     "iopub.status.busy": "2025-05-21T23:05:31.541422Z",
     "iopub.status.idle": "2025-05-21T23:05:31.560789Z",
     "shell.execute_reply": "2025-05-21T23:05:31.560789Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted House Price: 431942.36\n"
     ]
    }
   ],
   "source": [
    "# Inference function for the best model\n",
    "import numpy as np\n",
    "\n",
    "def predict_house_price(input_data):\n",
    "    # Convert input data to DataFrame\n",
    "    input_df = pd.DataFrame([input_data])\n",
    "    \n",
    "    # Preprocess the input data using the fitted preprocessor\n",
    "    processed_input = preprocessor.transform(input_df)\n",
    "    \n",
    "    # Predict using the best model\n",
    "    prediction = best_model.predict(processed_input)\n",
    "    \n",
    "    return prediction[0]\n",
    "\n",
    "# Example usage of the inference function\n",
    "sample_input = {\n",
    "    'longitude': -122.23,\n",
    "    'latitude': 37.88,\n",
    "    'housing_median_age': 41.0,\n",
    "    'total_rooms': 880.0,\n",
    "    'total_bedrooms': 129.0,\n",
    "    'population': 322.0,\n",
    "    'households': 126.0,\n",
    "    'median_income': 8.3252,\n",
    "    'ocean_proximity': 'NEAR BAY'\n",
    "}\n",
    "\n",
    "# Predicting house price for sample input\n",
    "predicted_price = predict_house_price(sample_input)\n",
    "print(f'Predicted House Price: {predicted_price}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcc5ed4",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "- Successfully developed a pipeline for house price prediction using various models.\n",
    "- Identified Random Forest as the best-performing model based on MAE and R-squared metrics.\n",
    "- Created a production-ready inference function to predict house prices on new data.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
